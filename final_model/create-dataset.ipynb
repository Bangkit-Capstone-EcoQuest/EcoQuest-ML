{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data hasil Koleksi dan Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import cv2\n",
    "import splitfolders\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pillow_heif import register_heif_opener\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Path Configuration ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = r\"D:\\1 Main File\\Project File\\Capstone Bangkit\\MyOwnTry\\AllData\"\n",
    "input_folder = os.path.join(base_folder, 'raw_data')  # Folder input (raw data)\n",
    "dataset_folder = os.path.join(base_folder, 'Dataset')  # Folder hasil split\n",
    "train_path = os.path.join(dataset_folder, 'train')  # Path folder train\n",
    "augmen_path = os.path.join(train_path, 'Augmen')  # Folder augmentasi\n",
    "final_size = (640, 640)  # Ukuran gambar seragam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Resize dan Rename ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_rename(input_folder, size, new_name_suffix):\n",
    "    print(\"Memproses gambar...\")\n",
    "    for class_folder in os.listdir(input_folder):\n",
    "        class_folder_path = os.path.join(input_folder, class_folder)\n",
    "        if os.path.isdir(class_folder_path):\n",
    "            for idx, file in enumerate(os.listdir(class_folder_path), start=1):\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    img_path = os.path.join(class_folder_path, file)\n",
    "                    img = cv2.imread(img_path)\n",
    "                    resized_img = cv2.resize(img, size)\n",
    "                    \n",
    "                    # Format nama file dengan menggantikan {class_folder} dan {idx}\n",
    "                    new_name = f\"{class_folder}{new_name_suffix}{idx}.jpg\"\n",
    "                    \n",
    "                    # Simpan gambar yang telah diresize dengan nama baru\n",
    "                    cv2.imwrite(os.path.join(class_folder_path, new_name), resized_img)\n",
    "                    \n",
    "                    # Hapus file lama setelah disimpan dengan nama baru\n",
    "                    os.remove(img_path)\n",
    "    print(f\"Semua gambar telah diproses dan disimpan ke {input_folder}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memproses gambar...\n",
      "Semua gambar telah diproses dan disimpan ke D:\\1 Main File\\Project File\\Capstone Bangkit\\MyOwnTry\\DataDummy\\raw_data.\n"
     ]
    }
   ],
   "source": [
    "resize_and_rename(input_folder, final_size, new_name_suffix=\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Split Dataset ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(input_folder, dataset_folder, ratio):\n",
    "    splitfolders.ratio(\n",
    "        input_folder,\n",
    "        output=dataset_folder,\n",
    "        seed=42,\n",
    "        ratio=ratio, # 70% train, 30% valid, 0% test\n",
    "        group_prefix=None\n",
    "    )\n",
    "    print(f\"Dataset berhasil dibagi ke dalam train, valid, dan test di {dataset_folder}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 650 files [00:03, 165.33 files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset berhasil dibagi ke dalam train, valid, dan test di D:\\1 Main File\\Project File\\Capstone Bangkit\\MyOwnTry\\DataDummy\\Dataset.\n"
     ]
    }
   ],
   "source": [
    "split_dataset(input_folder, dataset_folder, (0.7, 0.3, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Augmentasi Data ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(train_path, augmen_path, size, augmentation_count=5):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='constant',\n",
    "        cval=0\n",
    "    )\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=size,\n",
    "        batch_size=1,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    os.makedirs(augmen_path, exist_ok=True)\n",
    "    class_names = train_generator.class_indices\n",
    "    for class_name in class_names:\n",
    "        os.makedirs(os.path.join(augmen_path, class_name), exist_ok=True)\n",
    "\n",
    "    total_images = train_generator.samples\n",
    "    for i in range(total_images):\n",
    "        images, labels = next(train_generator)\n",
    "        class_index = labels[0].argmax()\n",
    "        class_name = list(class_names.keys())[list(class_names.values()).index(class_index)]\n",
    "        for aug_num in range(augmentation_count):\n",
    "            augmented_image = datagen.random_transform(images[0])\n",
    "            save_path = os.path.join(augmen_path, class_name, f\"{class_name}_aug_{i}_{aug_num}.jpg\")\n",
    "            tf.keras.preprocessing.image.save_img(save_path, augmented_image)\n",
    "    print(f\"Hasil augmentasi disimpan di {augmen_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 454 images belonging to 2 classes.\n",
      "Hasil augmentasi disimpan di D:\\1 Main File\\Project File\\Capstone Bangkit\\MyOwnTry\\DataDummy\\Dataset\\train\\Augmen.\n"
     ]
    }
   ],
   "source": [
    "augment_data(train_path, augmen_path, final_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Transfer Augmented Data ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_images_to_train(train_path, augmen_path):\n",
    "    for class_name in os.listdir(augmen_path):\n",
    "        augmen_class_path = os.path.join(augmen_path, class_name)\n",
    "        train_class_path = os.path.join(train_path, class_name)\n",
    "        os.makedirs(train_class_path, exist_ok=True)\n",
    "        for filename in os.listdir(augmen_class_path):\n",
    "            shutil.move(os.path.join(augmen_class_path, filename), os.path.join(train_class_path, filename))\n",
    "        if not os.listdir(augmen_class_path):\n",
    "            os.rmdir(augmen_class_path)\n",
    "    if not os.listdir(augmen_path):\n",
    "        os.rmdir(augmen_path)\n",
    "    print(\"Augmented data berhasil dipindahkan ke folder train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data berhasil dipindahkan ke folder train.\n"
     ]
    }
   ],
   "source": [
    "move_images_to_train(train_path, augmen_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data from Roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Path Dataset and Folder Output ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "roboflow_folder = r\"D:\\1 Main File\\Project File\\Capstone Bangkit\\MyOwnTry\\AllData\\RFdataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Preprocessing Roboflow Dataset ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_rfdataset(input_folder, output_folder, size):\n",
    "    \"\"\"\n",
    "    Preproses dataset Roboflow menggunakan anotasi.\n",
    "    \"\"\"\n",
    "    split_folders = ['train', 'val', 'test']\n",
    "    for split in split_folders:\n",
    "        split_path = os.path.join(input_folder, split)\n",
    "        output_path = os.path.join(output_folder, split)\n",
    "        csv_path = os.path.join(split_path, \"_annotations.csv\")\n",
    "\n",
    "        if not os.path.exists(csv_path):\n",
    "            print(f\"No annotation file for {split}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            img_name = row['filename']\n",
    "            category = row['class']\n",
    "            category_path = os.path.join(output_path, category)\n",
    "            os.makedirs(category_path, exist_ok=True)\n",
    "\n",
    "            source_img_path = os.path.join(split_path, img_name)\n",
    "            new_name = f\"{category}_RF_{idx + 1}.jpg\"\n",
    "            dest_img_path = os.path.join(category_path, new_name)\n",
    "\n",
    "            if os.path.exists(source_img_path):\n",
    "                resize_and_rename(input_folder, \n",
    "                                  final_size, \n",
    "                                  new_name_suffix=\"_rf_\")\n",
    "\n",
    "        os.remove(csv_path)\n",
    "        print(f\"Processed {split}. Annotations removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No annotation file for train. Skipping.\n",
      "No annotation file for val. Skipping.\n",
      "No annotation file for test. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# Jalankan preprocessing\n",
    "preprocess_rfdataset(roboflow_folder, dataset_folder, final_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data From Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Konfigurasi Path ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_folder = r\"D:\\1 Main File\\Project File\\Capstone Bangkit\\MyOwnTry\\AllData\\KaggleDataset\"\n",
    "subfolders = [\"PET\", \"HDPE\"]  # Subfolder dalam dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Preprocessing: Resize, Rename, dan Hapus Data Asli ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rename(kaggle_folder, final_size, new_name_suffix=\"_k_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Membagi Dataset ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset(kaggle_folder, dataset_folder, (0.7, 0.3, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Convert from HEIC to JPG ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder input dan outputr\n",
    "datasetcina_folder = r\"D:\\1 Main File\\Project File\\Capstone Bangkit\\MyOwnTry\\AllData\\DatasetCina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_heif_opener()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_heic_to_jpg(datasetcina_folder):\n",
    "    for file_name in os.listdir(datasetcina_folder):\n",
    "        file_path = os.path.join(datasetcina_folder, file_name)\n",
    "        \n",
    "        # Cek apakah file berformat HEIC\n",
    "        if file_name.lower().endswith(\".heic\"):\n",
    "            try:\n",
    "                # Buka file HEIC\n",
    "                img = Image.open(file_path)\n",
    "                \n",
    "                # Path untuk file JPG yang baru\n",
    "                output_file_name = f\"{os.path.splitext(file_name)[0]}.jpg\"\n",
    "                output_file_path = os.path.join(datasetcina_folder, output_file_name)\n",
    "                \n",
    "                # Cek apakah file JPG sudah ada\n",
    "                if not os.path.exists(output_file_path):\n",
    "                    # Simpan sebagai JPG\n",
    "                    img.save(output_file_path, \"JPEG\")\n",
    "                    \n",
    "                    # Hapus file HEIC asli\n",
    "                    os.remove(file_path)\n",
    "                    \n",
    "                    print(f\"Berhasil mengonversi: {file_name} -> {output_file_name}\")\n",
    "                else:\n",
    "                    print(f\"File JPG sudah ada, melewati: {output_file_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error memproses {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_heic_to_jpg(datasetcina_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rename(datasetcina_folder, final_size, new_name_suffix=\"_c_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Data Count==-="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung jumlah gambar per kelas\n",
    "def count_images_in_class(dataset_path):\n",
    "    # Menyimpan jumlah gambar per kelas untuk train, val, dan test\n",
    "    counts = {'train': {}, 'val': {}, 'test': {}}\n",
    "\n",
    "    # Folder yang ingin dicek (train, val, dan test)\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_folder_path = os.path.join(dataset_path, split)\n",
    "        if os.path.exists(split_folder_path):\n",
    "            for class_folder in os.listdir(split_folder_path):\n",
    "                class_folder_path = os.path.join(split_folder_path, class_folder)\n",
    "                if os.path.isdir(class_folder_path):\n",
    "                    counts[split][class_folder] = len([f for f in os.listdir(class_folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        else:\n",
    "            print(f\"Folder '{split}' tidak ditemukan di dataset.\")\n",
    "    \n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_class_counts = count_images_in_class(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah gambar per kelas untuk masing-masing split:\n",
      "\n",
      "Jumlah gambar di folder train:\n",
      "{'HDPE': 3588, 'PET': 3588}\n",
      "\n",
      "Jumlah gambar di folder val:\n",
      "{'HDPE': 813, 'PET': 813}\n",
      "\n",
      "Jumlah gambar di folder test:\n",
      "{'HDPE': 75, 'PET': 98}\n"
     ]
    }
   ],
   "source": [
    "print(\"Jumlah gambar per kelas untuk masing-masing split:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    print(f\"\\nJumlah gambar di folder {split}:\")\n",
    "    print(dataset_class_counts[split])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Balancing val ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_val_dataset(dataset_path, datasetcina_folder):\n",
    "    # Hitung jumlah gambar per kelas di val\n",
    "    val_counts = count_images_in_class(dataset_path)['val']\n",
    "    \n",
    "    # Cari kelas dengan jumlah data terbanyak\n",
    "    max_class = max(val_counts, key=val_counts.get)\n",
    "    max_count = val_counts[max_class]\n",
    "    \n",
    "    # Folder val dan train\n",
    "    val_folder = os.path.join(dataset_path, 'val')\n",
    "    train_folder = os.path.join(dataset_path, 'train')\n",
    "    \n",
    "    # Iterasi setiap kelas di val\n",
    "    for class_name, count in val_counts.items():\n",
    "        if count < max_count:\n",
    "            # Hitung selisih\n",
    "            difference = max_count - count\n",
    "            \n",
    "            # Path folder sumber di datasetcina\n",
    "            source_class_folder = os.path.join(datasetcina_folder, class_name)\n",
    "            \n",
    "            # Path folder tujuan di val\n",
    "            target_class_folder_val = os.path.join(val_folder, class_name)\n",
    "            os.makedirs(target_class_folder_val, exist_ok=True)\n",
    "            \n",
    "            # Pindahkan file dari datasetcina ke val\n",
    "            files_to_move = [f for f in os.listdir(source_class_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:difference]\n",
    "            for file_name in files_to_move:\n",
    "                shutil.move(os.path.join(source_class_folder, file_name), os.path.join(target_class_folder_val, file_name))\n",
    "    \n",
    "    # Pindahkan sisa file dari datasetcina ke train\n",
    "    for class_name in os.listdir(datasetcina_folder):\n",
    "        source_class_folder = os.path.join(datasetcina_folder, class_name)\n",
    "        target_class_folder_train = os.path.join(train_folder, class_name)\n",
    "        os.makedirs(target_class_folder_train, exist_ok=True)\n",
    "        \n",
    "        files_to_move = [f for f in os.listdir(source_class_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        for file_name in files_to_move:\n",
    "            shutil.move(os.path.join(source_class_folder, file_name), os.path.join(target_class_folder_train, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_val_dataset(dataset_folder, datasetcina_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_class_counts = count_images_in_class(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Jumlah gambar per kelas untuk masing-masing split:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    print(f\"\\nJumlah gambar di folder {split}:\")\n",
    "    print(dataset_class_counts[split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_and_balance_data(train_path, variations_per_image):\n",
    "    # Inisialisasi ImageDataGenerator\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=27,\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='constant',\n",
    "        cval=0\n",
    "    )\n",
    "\n",
    "    # Ambil nama kelas dan hitung jumlah gambar per kelas\n",
    "    class_counts = {}\n",
    "    class_names = os.listdir(train_path)\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_folder = os.path.join(train_path, class_name)\n",
    "        if os.path.isdir(class_folder):\n",
    "            class_image_count = len([f for f in os.listdir(class_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            class_counts[class_name] = class_image_count\n",
    "\n",
    "    # Tentukan target_class_count dari kelas dengan jumlah gambar terbanyak\n",
    "    target_class_name = max(class_counts, key=class_counts.get)\n",
    "    target_class_count = class_counts[target_class_name]\n",
    "\n",
    "    for class_name, class_image_count in class_counts.items():\n",
    "        if class_image_count < target_class_count:\n",
    "            # Hitung selisih jumlah gambar yang dibutuhkan\n",
    "            num_images_to_generate = target_class_count - class_image_count\n",
    "            print(f\"Augmentasi untuk kelas {class_name}: {num_images_to_generate} gambar\")\n",
    "\n",
    "            # Loop augmentasi untuk setiap gambar di kelas\n",
    "            generated_count = 0\n",
    "            class_images = [f for f in os.listdir(os.path.join(train_path, class_name)) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "            for image_file in class_images:\n",
    "                if generated_count >= num_images_to_generate:\n",
    "                    break\n",
    "\n",
    "                # Baca gambar\n",
    "                image_path = os.path.join(train_path, class_name, image_file)\n",
    "                img = cv2.imread(image_path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (640, 640))\n",
    "                img = img.reshape((1,) + img.shape)  # Reshape untuk generator\n",
    "\n",
    "                # Generate gambar augmentasi (maksimum `variations_per_image` per gambar)\n",
    "                for _ in range(variations_per_image):\n",
    "                    if generated_count < num_images_to_generate:\n",
    "                        # Simpan augmentasi langsung ke folder kelas\n",
    "                        for batch in datagen.flow(img, batch_size=1, save_to_dir=os.path.join(train_path, class_name), save_prefix='aug', save_format='jpg'):\n",
    "                            generated_count += 1\n",
    "                            break  # Hentikan setelah satu gambar dihasilkan\n",
    "\n",
    "            print(f\"Augmentasi untuk {class_name} selesai, total gambar: {target_class_count}\")\n",
    "\n",
    "    print(\"Augmentasi selesai untuk semua kelas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_and_balance_data(train_path, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_images_in_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset_class_counts \u001b[38;5;241m=\u001b[39m count_images_in_class(dataset_folder)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'count_images_in_class' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_class_counts = count_images_in_class(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Jumlah gambar per kelas untuk masing-masing split:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    print(f\"\\nJumlah gambar di folder {split}:\")\n",
    "    print(dataset_class_counts[split])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Shuffle dataset ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_dataset(dataset_path):\n",
    "    \"\"\"\n",
    "    Mengacak urutan data di setiap kelas dalam dataset.\n",
    "    \n",
    "    Args:\n",
    "    - dataset_path: Path ke folder utama dataset yang memiliki subfolder train, val, dan test.\n",
    "    \"\"\"\n",
    "    # Subfolder yang ingin diacak\n",
    "    splits = ['train', 'val', 'test']\n",
    "\n",
    "    for split in splits:\n",
    "        split_folder_path = os.path.join(dataset_path, split)\n",
    "        if os.path.exists(split_folder_path):\n",
    "            # Iterasi setiap folder kelas\n",
    "            for class_name in os.listdir(split_folder_path):\n",
    "                class_folder_path = os.path.join(split_folder_path, class_name)\n",
    "                if os.path.isdir(class_folder_path):\n",
    "                    # Ambil semua file gambar dalam folder kelas\n",
    "                    images = [f for f in os.listdir(class_folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                    \n",
    "                    # Acak urutan gambar\n",
    "                    random.shuffle(images)\n",
    "\n",
    "                    # Pindahkan gambar ke folder sementara untuk mengacak\n",
    "                    temp_folder = os.path.join(class_folder_path, 'temp')\n",
    "                    os.makedirs(temp_folder, exist_ok=True)\n",
    "\n",
    "                    for image in images:\n",
    "                        shutil.move(os.path.join(class_folder_path, image), os.path.join(temp_folder, image))\n",
    "\n",
    "                    # Pindahkan gambar kembali ke folder kelas dari folder sementara\n",
    "                    for image in os.listdir(temp_folder):\n",
    "                        shutil.move(os.path.join(temp_folder, image), os.path.join(class_folder_path, image))\n",
    "\n",
    "                    # Hapus folder sementara\n",
    "                    os.rmdir(temp_folder)\n",
    "\n",
    "                    # Cetak pesan untuk setiap kelas yang telah diacak\n",
    "                    print(f\"Dataset di folder '{split}' telah diacak untuk kelas '{class_name}'.\")\n",
    "        else:\n",
    "            print(f\"Folder '{split}' tidak ditemukan di dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset di folder 'train' telah diacak untuk kelas 'HDPE'.\n",
      "Dataset di folder 'train' telah diacak untuk kelas 'PET'.\n",
      "Dataset di folder 'val' telah diacak untuk kelas 'HDPE'.\n",
      "Dataset di folder 'val' telah diacak untuk kelas 'PET'.\n",
      "Dataset di folder 'test' telah diacak untuk kelas 'HDPE'.\n",
      "Dataset di folder 'test' telah diacak untuk kelas 'PET'.\n"
     ]
    }
   ],
   "source": [
    "shuffle_dataset(dataset_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
