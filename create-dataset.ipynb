{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data hasil Koleksi dan Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import cv2\n",
    "import splitfolders\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pillow_heif import register_heif_opener\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Path Configuration ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = r\"D:\\1 Main File\\Project File\\Capstone Bangkit\\MakeDataset6\"\n",
    "input_folder = os.path.join(base_folder, 'raw_data')\n",
    "dataset_folder = os.path.join(base_folder, 'dataset')\n",
    "train_path = os.path.join(dataset_folder, 'train')\n",
    "augmen_path = os.path.join(train_path, 'Augmen')\n",
    "final_size = (640, 640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Resize dan Rename ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_rename(input_folder, size, new_name_suffix):\n",
    "    print(\"Processing image...\")\n",
    "    for class_folder in os.listdir(input_folder):\n",
    "        class_folder_path = os.path.join(input_folder, class_folder)\n",
    "        if os.path.isdir(class_folder_path):\n",
    "            for idx, file in enumerate(os.listdir(class_folder_path), start=1):\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    img_path = os.path.join(class_folder_path, file)\n",
    "                    img = cv2.imread(img_path)\n",
    "                    resized_img = cv2.resize(img, size)\n",
    "\n",
    "                    new_name = f\"{class_folder}{new_name_suffix}{idx}.jpg\"\n",
    "                    \n",
    "                    cv2.imwrite(os.path.join(class_folder_path, new_name), resized_img)\n",
    "                    \n",
    "                    os.remove(img_path)\n",
    "    print(f\"All image has been processed and saved in {input_folder}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image...\n",
      "All image has been processed and saved in D:\\1 Main File\\Project File\\Capstone Bangkit\\MakeDataset6\\raw_data.\n"
     ]
    }
   ],
   "source": [
    "resize_and_rename(input_folder, final_size, new_name_suffix=\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Split Dataset ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(input_folder, dataset_folder, ratio):\n",
    "    splitfolders.ratio(\n",
    "        input_folder,\n",
    "        output=dataset_folder,\n",
    "        seed=42,\n",
    "        ratio=ratio,\n",
    "        group_prefix=None\n",
    "    )\n",
    "    print(f\"Dataset splited to train, val, and test in {dataset_folder}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 699 files [00:00, 1134.85 files/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splited to train, val, and test in D:\\1 Main File\\Project File\\Capstone Bangkit\\MakeDataset6\\dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "split_dataset(input_folder, dataset_folder, (0.4, 0.5, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Augmentasi Data ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(train_path, augmen_path, size, augmentation_count=30):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        zoom_range=0.1,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='constant',\n",
    "        cval=0\n",
    "    )\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=size,\n",
    "        batch_size=1,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    os.makedirs(augmen_path, exist_ok=True)\n",
    "    class_names = train_generator.class_indices\n",
    "    for class_name in class_names:\n",
    "        os.makedirs(os.path.join(augmen_path, class_name), exist_ok=True)\n",
    "\n",
    "    total_images = train_generator.samples\n",
    "    for i in range(total_images):\n",
    "        images, labels = next(train_generator)\n",
    "        class_index = labels[0].argmax()\n",
    "        class_name = list(class_names.keys())[list(class_names.values()).index(class_index)]\n",
    "        for aug_num in range(augmentation_count):\n",
    "            augmented_image = datagen.random_transform(images[0])\n",
    "            save_path = os.path.join(augmen_path, class_name, f\"{class_name}_aug_{i}_{aug_num}.jpg\")\n",
    "            tf.keras.preprocessing.image.save_img(save_path, augmented_image)\n",
    "    print(f\"Augmented data saved in {augmen_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 278 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data saved in D:\\1 Main File\\Project File\\Capstone Bangkit\\MakeDataset6\\dataset\\train\\Augmen.\n"
     ]
    }
   ],
   "source": [
    "augment_data(train_path, augmen_path, final_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Transfer Augmented Data ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_images_to_train(train_path, augmen_path):\n",
    "    for class_name in os.listdir(augmen_path):\n",
    "        augmen_class_path = os.path.join(augmen_path, class_name)\n",
    "        train_class_path = os.path.join(train_path, class_name)\n",
    "        os.makedirs(train_class_path, exist_ok=True)\n",
    "        for filename in os.listdir(augmen_class_path):\n",
    "            shutil.move(os.path.join(augmen_class_path, filename), os.path.join(train_class_path, filename))\n",
    "        if not os.listdir(augmen_class_path):\n",
    "            os.rmdir(augmen_class_path)\n",
    "    if not os.listdir(augmen_path):\n",
    "        os.rmdir(augmen_path)\n",
    "    print(\"Augmented data transfered to train folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data transfered to train folder\n"
     ]
    }
   ],
   "source": [
    "move_images_to_train(train_path, augmen_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data from Roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Path Dataset and Folder Output ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "roboflow_folder = r\"D:\\1 Main File\\Project File\\Capstone Bangkit\\MyOwnTry\\AllData\\RFdataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Preprocessing Roboflow Dataset ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_rfdataset(input_folder, output_folder, size):\n",
    "    split_folders = ['train', 'val', 'test']\n",
    "    for split in split_folders:\n",
    "        split_path = os.path.join(input_folder, split)\n",
    "        output_path = os.path.join(output_folder, split)\n",
    "        csv_path = os.path.join(split_path, \"_annotations.csv\")\n",
    "\n",
    "        if not os.path.exists(csv_path):\n",
    "            print(f\"No annotation file for {split}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            img_name = row['filename']\n",
    "            category = row['class']\n",
    "            category_path = os.path.join(output_path, category)\n",
    "            os.makedirs(category_path, exist_ok=True)\n",
    "\n",
    "            source_img_path = os.path.join(split_path, img_name)\n",
    "            new_name = f\"{category}_RF_{idx + 1}.jpg\"\n",
    "            dest_img_path = os.path.join(category_path, new_name)\n",
    "\n",
    "            if os.path.exists(source_img_path):\n",
    "                resize_and_rename(input_folder, \n",
    "                                  final_size, \n",
    "                                  new_name_suffix=\"_rf_\")\n",
    "\n",
    "        os.remove(csv_path)\n",
    "        print(f\"Processed {split}. Annotations removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_rfdataset(roboflow_folder, dataset_folder, final_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data From Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Konfigurasi Path ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_folder = r\"D:\\1 Main File\\Project File\\Capstone Bangkit\\MyOwnTry\\AllData\\KaggleDataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Preprocessing: Resize, Rename, dan Hapus Data Asli ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rename(kaggle_folder, final_size, new_name_suffix=\"_k_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Membagi Dataset ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset(kaggle_folder, dataset_folder, (0.7, 0.3, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Convert from HEIC to JPG ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetcina_folder = r\"D:\\1 Main File\\Project File\\Capstone Bangkit\\MyOwnTry\\AllData\\DatasetCina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_heif_opener()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_heic_to_jpg(datasetcina_folder):\n",
    "    for file_name in os.listdir(datasetcina_folder):\n",
    "        file_path = os.path.join(datasetcina_folder, file_name)\n",
    "        \n",
    "        if file_name.lower().endswith(\".heic\"):\n",
    "            try:\n",
    "                img = Image.open(file_path)\n",
    "                \n",
    "                output_file_name = f\"{os.path.splitext(file_name)[0]}.jpg\"\n",
    "                output_file_path = os.path.join(datasetcina_folder, output_file_name)\n",
    "                \n",
    "                if not os.path.exists(output_file_path):\n",
    "                    img.save(output_file_path, \"JPEG\")\n",
    "\n",
    "                    os.remove(file_path)\n",
    "                    \n",
    "                    print(f\"Convertion successfull: {file_name} -> {output_file_name}\")\n",
    "                else:\n",
    "                    print(f\"JPG file exsist, skip: {output_file_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_heic_to_jpg(datasetcina_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rename(datasetcina_folder, final_size, new_name_suffix=\"_c_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Data Count==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung jumlah gambar per kelas\n",
    "def count_images_in_class(dataset_path):\n",
    "    counts = {'train': {}, 'val': {}, 'test': {}}\n",
    "\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_folder_path = os.path.join(dataset_path, split)\n",
    "        if os.path.exists(split_folder_path):\n",
    "            for class_folder in os.listdir(split_folder_path):\n",
    "                class_folder_path = os.path.join(split_folder_path, class_folder)\n",
    "                if os.path.isdir(class_folder_path):\n",
    "                    counts[split][class_folder] = len([f for f in os.listdir(class_folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        else:\n",
    "            print(f\"Folder '{split}' not found.\")\n",
    "    \n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_class_counts = count_images_in_class(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of image each class for each split:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    print(f\"\\nNumber of picture in folder {split}:\")\n",
    "    print(dataset_class_counts[split])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Balancing val ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_val_dataset(dataset_path, datasetcina_folder):\n",
    "    val_counts = count_images_in_class(dataset_path)['val']\n",
    "\n",
    "    max_class = max(val_counts, key=val_counts.get)\n",
    "    max_count = val_counts[max_class]\n",
    "\n",
    "    val_folder = os.path.join(dataset_path, 'val')\n",
    "    train_folder = os.path.join(dataset_path, 'train')\n",
    "\n",
    "    for class_name, count in val_counts.items():\n",
    "        if count < max_count:\n",
    "            difference = max_count - count\n",
    "\n",
    "            source_class_folder = os.path.join(datasetcina_folder, class_name)\n",
    " \n",
    "            target_class_folder_val = os.path.join(val_folder, class_name)\n",
    "            os.makedirs(target_class_folder_val, exist_ok=True)\n",
    " \n",
    "            files_to_move = [f for f in os.listdir(source_class_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:difference]\n",
    "            for file_name in files_to_move:\n",
    "                shutil.move(os.path.join(source_class_folder, file_name), os.path.join(target_class_folder_val, file_name))\n",
    "\n",
    "    for class_name in os.listdir(datasetcina_folder):\n",
    "        source_class_folder = os.path.join(datasetcina_folder, class_name)\n",
    "        target_class_folder_train = os.path.join(train_folder, class_name)\n",
    "        os.makedirs(target_class_folder_train, exist_ok=True)\n",
    "        \n",
    "        files_to_move = [f for f in os.listdir(source_class_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        for file_name in files_to_move:\n",
    "            shutil.move(os.path.join(source_class_folder, file_name), os.path.join(target_class_folder_train, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_val_dataset(dataset_folder, datasetcina_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_class_counts = count_images_in_class(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of image each class for each split:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    print(f\"\\nNumber of picture in folder {split}:\")\n",
    "    print(dataset_class_counts[split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_and_balance_data(train_path, variations_per_image):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=27,\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='constant',\n",
    "        cval=0\n",
    "    )\n",
    "\n",
    "    class_counts = {}\n",
    "    class_names = os.listdir(train_path)\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_folder = os.path.join(train_path, class_name)\n",
    "        if os.path.isdir(class_folder):\n",
    "            class_image_count = len([f for f in os.listdir(class_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            class_counts[class_name] = class_image_count\n",
    "\n",
    "    target_class_name = max(class_counts, key=class_counts.get)\n",
    "    target_class_count = class_counts[target_class_name]\n",
    "\n",
    "    for class_name, class_image_count in class_counts.items():\n",
    "        if class_image_count < target_class_count:\n",
    "            num_images_to_generate = target_class_count - class_image_count\n",
    "            print(f\"Augmentation for class {class_name}: {num_images_to_generate} image\")\n",
    "\n",
    "            generated_count = 0\n",
    "            class_images = [f for f in os.listdir(os.path.join(train_path, class_name)) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "            for image_file in class_images:\n",
    "                if generated_count >= num_images_to_generate:\n",
    "                    break\n",
    "\n",
    "                image_path = os.path.join(train_path, class_name, image_file)\n",
    "                img = cv2.imread(image_path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (640, 640))\n",
    "                img = img.reshape((1,) + img.shape)\n",
    "\n",
    "                for _ in range(variations_per_image):\n",
    "                    if generated_count < num_images_to_generate:\n",
    "                        for batch in datagen.flow(img, batch_size=1, save_to_dir=os.path.join(train_path, class_name), save_prefix='aug', save_format='jpg'):\n",
    "                            generated_count += 1\n",
    "                            break \n",
    "\n",
    "            print(f\"Augmentation for {class_name} Finish, total image: {target_class_count}\")\n",
    "\n",
    "    print(\"Data balanced!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_and_balance_data(train_path, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_class_counts = count_images_in_class(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of image each class for each split:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    print(f\"\\nNumber of picture in folder {split}:\")\n",
    "    print(dataset_class_counts[split])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Data balancing more classes ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_data(dataset_path, max_train=3588, max_val=813):\n",
    "    splits = ['train', 'val', 'test']\n",
    "\n",
    "    train_folder_path = os.path.join(dataset_path, 'train')\n",
    "    for class_name in os.listdir(train_folder_path):\n",
    "        class_folder_path = os.path.join(train_folder_path, class_name)\n",
    "        if os.path.isdir(class_folder_path):\n",
    "            train_images = [f for f in os.listdir(class_folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            train_count = len(train_images)\n",
    "\n",
    "            if train_count > max_train:\n",
    "                excess_count = train_count - max_train\n",
    "                print(f\"Memindahkan {excess_count} gambar dari '{class_name}' di train ke val.\")\n",
    "\n",
    "                val_class_folder_path = os.path.join(dataset_path, 'val', class_name)\n",
    "                os.makedirs(val_class_folder_path, exist_ok=True)\n",
    "\n",
    "                for image in train_images[:excess_count]:\n",
    "                    shutil.move(os.path.join(class_folder_path, image), os.path.join(val_class_folder_path, image))\n",
    "\n",
    "            val_images = [f for f in os.listdir(val_class_folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            val_count = len(val_images)\n",
    "\n",
    "            if val_count > max_val:\n",
    "                excess_count = val_count - max_val\n",
    "                print(f\"Memindahkan {excess_count} gambar dari '{class_name}' di val ke test.\")\n",
    "\n",
    "                test_class_folder_path = os.path.join(dataset_path, 'test', class_name)\n",
    "                os.makedirs(test_class_folder_path, exist_ok=True)\n",
    "\n",
    "                for image in val_images[:excess_count]:\n",
    "                    shutil.move(os.path.join(val_class_folder_path, image), os.path.join(test_class_folder_path, image))\n",
    "\n",
    "    print(\"Distribusi data selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memindahkan 752 gambar dari 'PP' di train ke val.\n",
      "Memindahkan 115 gambar dari 'PP' di val ke test.\n",
      "Memindahkan 690 gambar dari 'PS' di train ke val.\n",
      "Memindahkan 50 gambar dari 'PS' di val ke test.\n",
      "Distribusi data selesai.\n"
     ]
    }
   ],
   "source": [
    "distribute_data(dataset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### === Shuffle dataset ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_dataset(dataset_path):\n",
    "    splits = ['train', 'val', 'test']\n",
    "\n",
    "    for split in splits:\n",
    "        split_folder_path = os.path.join(dataset_path, split)\n",
    "        if os.path.exists(split_folder_path):\n",
    "            for class_name in os.listdir(split_folder_path):\n",
    "                class_folder_path = os.path.join(split_folder_path, class_name)\n",
    "                if os.path.isdir(class_folder_path):\n",
    "                    images = [f for f in os.listdir(class_folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                    \n",
    "                    random.shuffle(images)\n",
    "\n",
    "                    temp_folder = os.path.join(class_folder_path, 'temp')\n",
    "                    os.makedirs(temp_folder, exist_ok=True)\n",
    "\n",
    "                    for image in images:\n",
    "                        shutil.move(os.path.join(class_folder_path, image), os.path.join(temp_folder, image))\n",
    "\n",
    "                    for image in os.listdir(temp_folder):\n",
    "                        shutil.move(os.path.join(temp_folder, image), os.path.join(class_folder_path, image))\n",
    "\n",
    "                    os.rmdir(temp_folder)\n",
    "\n",
    "                    print(f\"Dataset in '{split}' has been randomized for class '{class_name}'.\")\n",
    "        else:\n",
    "            print(f\"Folder '{split}' not found at dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_dataset(dataset_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
